# QuestionVulnerabilityML

An innovative educational initiative has led to the development of a 
unique software tool called QuestionVulnerabilityML. This project is aimed 
at educators and academic institutions, focusing on evaluating the 
vulnerability of examination questions to answers generated by advanced 
language models. The primary goal is to assess the integrity of questions 
in an era where AI-driven academic assistance is readily available.

QuestionVulnerabilityML is a sophisticated application that integrates 
cutting-edge natural language processing algorithms and language models. 
It is designed to simulate student responses to various types of 
examination questions, thereby providing an analysis of how susceptible 
these questions are to being accurately answered by AI models.

Features:

Question Analysis Engine: At its core, the tool has a powerful analysis 
engine capable of processing a wide range of question types – from 
straightforward factual questions to complex analytical or problem-solving 
queries.

Language Model Integration: QuestionVulnerabilityML utilizes advanced 
language models to generate responses to the input questions. This 
integration is the key to evaluating the complexity and robustness of the 
questions against AI capabilities.

Vulnerability Scoring System: Each question is assigned a vulnerability 
score based on the accuracy and relevance of the language model's 
response. Higher scores indicate a greater likelihood that the question 
can be successfully answered by AI, suggesting a potential risk of 
academic dishonesty.

Feedback and Recommendations: Beyond scoring, the tool provides detailed 
feedback on each question, including recommendations for increasing its 
complexity or restructuring it to reduce AI exploitability.

User-Friendly Interface: The application features an intuitive interface 
for educators to input questions, view scores, and receive feedback. This 
interface is designed to be accessible for users with varying levels of 
technical expertise.

Project Deliverables:

Design Document (20 pts) - A comprehensive document that details the 
functional and technical aspects of QuestionVulnerabilityML. It should 
include at least 2 User Stories and 10-15 use cases, covering 
functionalities such as question input, AI response generation, 
vulnerability assessment, and feedback provision.

Working Prototype (40 pts) - A working prototype of 
QuestionVulnerabilityML, functional from the command line. It should 
demonstrate the tool’s ability to accept question inputs, process them 
through the language model, and display vulnerability scores and feedback. 
The prototype should be developed with potential future expansion in mind. 
All team members must contribute to the codebase, verified through a 
source control repository link or screenshots.

Unit Tests (30 pts) - A minimum of two unit tests per use case (20-30 
total) to ensure the functionality of each aspect of the application. 
These tests should cover a range of scenarios, including successful 
analysis, handling of ambiguous or poorly structured questions, and system 
errors. The unit test code should be part of the source control 
repository. A detailed spreadsheet cataloging each unit test should be 
maintained, including test names, descriptions, corresponding use cases, 
inputs, expected outputs, and criteria for test success or failure.

Other Documents (10 pts) - A README.txt file providing detailed 
instructions for setting up and using QuestionVulnerabilityML from the 
command line. This document should be exhaustive, ensuring users can 
operate the application without additional external information. Note any 
prerequisites necessary for running the software. In addition, include a 
comprehensive report of the team’s meeting logs throughout the development 
process.


